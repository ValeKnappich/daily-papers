<!DOCTYPE html><!--gxhlgh8RQTNWLfxX8IBZI--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/favicon.png"/><link rel="stylesheet" href="/daily-papers/_next/static/css/91381fdc9cdd988f.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/daily-papers/_next/static/chunks/webpack-fc8e233cfa9e6f69.js"/><script src="/daily-papers/_next/static/chunks/4bd1b696-c49c6f05a40ba469.js" async=""></script><script src="/daily-papers/_next/static/chunks/964-dff8478de30a6510.js" async=""></script><script src="/daily-papers/_next/static/chunks/main-app-00615a32e0ffc0ce.js" async=""></script><script src="/daily-papers/_next/static/chunks/874-437a265a67d6cfee.js" async=""></script><script src="/daily-papers/_next/static/chunks/app/archive/%5Bdate%5D/page-a387a16caeea677c.js" async=""></script><script src="/daily-papers/_next/static/chunks/app/layout-5028dafa153b323a.js" async=""></script><title>Daily Papers</title><meta name="description" content="Stay updated with the latest research papers"/><link rel="icon" href="/daily-papers/favicon.ico" type="image/x-icon" sizes="1024x1024"/><script src="/daily-papers/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="bg-zinc-50 dark:bg-zinc-950 text-zinc-900 dark:text-zinc-100 min-h-screen"><div hidden=""><!--$--><!--/$--></div><header class="w-full py-4 border-b border-zinc-200 dark:border-zinc-800 mb-8"><div class="max-w-6xl mx-auto px-4 flex items-center justify-between"><a class="flex items-center gap-3 hover:opacity-80 transition-opacity" href="/daily-papers"><img src="/favicon.png" alt="favicon" width="28" height="28" class="rounded"/><span class="font-bold text-lg tracking-tight">Daily Papers</span></a><div class="flex items-center gap-4"><div class="relative"><button class="px-3 py-1 rounded bg-zinc-100 dark:bg-zinc-800 border border-zinc-300 dark:border-zinc-700 text-sm font-medium hover:bg-zinc-200 dark:hover:bg-zinc-700 focus:outline-none" aria-haspopup="listbox" aria-expanded="false">Past Days<span class="ml-2">▼</span></button></div><a href="https://github.com/kvn2fe/daily-papers" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline text-sm">GitHub</a></div></div></header><main><main class="max-w-6xl mx-auto py-10 px-4"><h1 class="text-2xl font-extrabold mb-8 tracking-tight text-center">Papers for <!-- -->2025-05-27</h1><div class="prose dark:prose-invert border rounded p-4 bg-white dark:bg-zinc-900 mb-8"><div class="mb-8"><h2 class="text-xl font-semibold mb-1">1<!-- -->. <!-- -->Research on feature fusion and multimodal patent text based on graph
  attention network</h2><div class="text-sm text-gray-600 mb-1"><b>Authors:</b> <!-- -->Zhenzhen Song, Ziwei Liu, Hongji Li</div><div class="text-sm text-gray-600 mb-1"><b>Published:</b> <!-- -->2025-05-26T16:32:43Z</div><div class="text-sm text-gray-600 mb-2"><b>Link:</b> <a href="http://arxiv.org/abs/2505.20188v1" class="text-blue-600 hover:underline" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2505.20188v1</a></div><div class="whitespace-pre-line">Aiming at the problems of cross-modal feature fusion, low efficiency of long text modeling and lack of hierarchical semantic coherence in patent text semantic mining, this study proposes HGM-Net, a deep learning framework that integrates Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention Network (M-GAT) and Multi-Granularity Sparse Attention (MSA), which builds a dynamic mask, contrast and cross-structural similarity constraints on the word, sentence and paragraph hierarchies through HCL. Contrast and cross-structural similarity constraints are constructed at the word and paragraph levels by HCL to strengthen the local semantic and global thematic consistency of patent text; M-GAT models patent classification codes, citation relations and text semantics as heterogeneous graph structures, and achieves dynamic fusion of multi-source features by cross-modal gated attention; MSA adopts a hierarchical sparsity strategy to optimize the computational efficiency of long text modeling at word, phrase, sentence and paragraph granularity. Experiments show that the framework demonstrates significant advantages over existing deep learning methods in tasks such as patent classification and similarity matching, and provides a solution with both theoretical innovation and practical value for solving the problems of patent examination efficiency improvement and technology relevance mining.</div></div></div><div class="mt-8"><a class="text-gray-700 hover:underline" href="/daily-papers">← Back to Today</a></div></main><!--$--><!--/$--></main><footer class="w-full py-6 border-t border-zinc-200 dark:border-zinc-800 mt-12 text-center text-xs text-zinc-500">© <!-- -->2025<!-- --> Daily Papers. All rights reserved.</footer><script src="/daily-papers/_next/static/chunks/webpack-fc8e233cfa9e6f69.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[6874,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"408\",\"static/chunks/app/archive/%5Bdate%5D/page-a387a16caeea677c.js\"],\"\"]\n3:I[5838,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"177\",\"static/chunks/app/layout-5028dafa153b323a.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n7:I[9665,[],\"OutletBoundary\"]\n9:I[4911,[],\"AsyncMetadataOutlet\"]\nb:I[9665,[],\"ViewportBoundary\"]\nd:I[9665,[],\"MetadataBoundary\"]\ne:\"$Sreact.suspense\"\n10:I[8393,[],\"\"]\n:HL[\"/daily-papers/_next/static/css/91381fdc9cdd988f.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"gxhlgh8RQTNWLfxX8IBZI\",\"p\":\"/daily-papers\",\"c\":[\"\",\"archive\",\"2025-05-27\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"archive\",{\"children\":[[\"date\",\"2025-05-27\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/daily-papers/_next/static/css/91381fdc9cdd988f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"bg-zinc-50 dark:bg-zinc-950 text-zinc-900 dark:text-zinc-100 min-h-screen\",\"children\":[[\"$\",\"header\",null,{\"className\":\"w-full py-4 border-b border-zinc-200 dark:border-zinc-800 mb-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto px-4 flex items-center justify-between\",\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/\",\"className\":\"flex items-center gap-3 hover:opacity-80 transition-opacity\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/favicon.png\",\"alt\":\"favicon\",\"width\":28,\"height\":28,\"className\":\"rounded\"}],[\"$\",\"span\",null,{\"className\":\"font-bold text-lg tracking-tight\",\"children\":\"Daily Papers\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"$L3\",null,{}],[\"$\",\"a\",null,{\"href\":\"https://github.com/kvn2fe/daily-papers\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:underline text-sm\",\"children\":\"GitHub\"}]]}]]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"w-full py-6 border-t border-zinc-200 dark:border-zinc-800 mt-12 text-center text-xs text-zinc-500\",\"children\":[\"© \",2025,\" Daily Papers. All rights reserved.\"]}]]}]}]]}],{\"children\":[\"archive\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"date\",\"2025-05-27\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",null,[\"$\",\"$L7\",null,{\"children\":[\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],null],[\"$\",\"$Ld\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$e\",null,{\"fallback\":null,\"children\":\"$Lf\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$10\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:T585,"])</script><script>self.__next_f.push([1,"Aiming at the problems of cross-modal feature fusion, low efficiency of long text modeling and lack of hierarchical semantic coherence in patent text semantic mining, this study proposes HGM-Net, a deep learning framework that integrates Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention Network (M-GAT) and Multi-Granularity Sparse Attention (MSA), which builds a dynamic mask, contrast and cross-structural similarity constraints on the word, sentence and paragraph hierarchies through HCL. Contrast and cross-structural similarity constraints are constructed at the word and paragraph levels by HCL to strengthen the local semantic and global thematic consistency of patent text; M-GAT models patent classification codes, citation relations and text semantics as heterogeneous graph structures, and achieves dynamic fusion of multi-source features by cross-modal gated attention; MSA adopts a hierarchical sparsity strategy to optimize the computational efficiency of long text modeling at word, phrase, sentence and paragraph granularity. Experiments show that the framework demonstrates significant advantages over existing deep learning methods in tasks such as patent classification and similarity matching, and provides a solution with both theoretical innovation and practical value for solving the problems of patent examination efficiency improvement and technology relevance mining."])</script><script>self.__next_f.push([1,"6:[\"$\",\"main\",null,{\"className\":\"max-w-6xl mx-auto py-10 px-4\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-2xl font-extrabold mb-8 tracking-tight text-center\",\"children\":[\"Papers for \",\"2025-05-27\"]}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert border rounded p-4 bg-white dark:bg-zinc-900 mb-8\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"mb-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-xl font-semibold mb-1\",\"children\":[1,\". \",\"Research on feature fusion and multimodal patent text based on graph\\n  attention network\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-600 mb-1\",\"children\":[[\"$\",\"b\",null,{\"children\":\"Authors:\"}],\" \",\"Zhenzhen Song, Ziwei Liu, Hongji Li\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-600 mb-1\",\"children\":[[\"$\",\"b\",null,{\"children\":\"Published:\"}],\" \",\"2025-05-26T16:32:43Z\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-600 mb-2\",\"children\":[[\"$\",\"b\",null,{\"children\":\"Link:\"}],\" \",[\"$\",\"a\",null,{\"href\":\"http://arxiv.org/abs/2505.20188v1\",\"className\":\"text-blue-600 hover:underline\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"http://arxiv.org/abs/2505.20188v1\"}]]}],[\"$\",\"div\",null,{\"className\":\"whitespace-pre-line\",\"children\":\"$11\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8\",\"children\":[\"$\",\"$L2\",null,{\"href\":\"/\",\"className\":\"text-gray-700 hover:underline\",\"children\":\"← Back to Today\"}]}]]}]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:null\n"])</script><script>self.__next_f.push([1,"12:I[8175,[],\"IconMark\"]\na:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Daily Papers\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Stay updated with the latest research papers\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/daily-papers/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"1024x1024\"}],[\"$\",\"$L12\",\"3\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"f:\"$a:metadata\"\n"])</script></body></html>
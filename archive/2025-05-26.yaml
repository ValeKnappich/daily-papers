date: '2025-05-26'
papers:
- title: "Research on feature fusion and multimodal patent text based on graph\n \
    \ attention network"
  authors:
  - Zhenzhen Song
  - Ziwei Liu
  - Hongji Li
  summary: Aiming at the problems of cross-modal feature fusion, low efficiency of
    long text modeling and lack of hierarchical semantic coherence in patent text
    semantic mining, this study proposes HGM-Net, a deep learning framework that integrates
    Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention Network (M-GAT)
    and Multi-Granularity Sparse Attention (MSA), which builds a dynamic mask, contrast
    and cross-structural similarity constraints on the word, sentence and paragraph
    hierarchies through HCL. Contrast and cross-structural similarity constraints
    are constructed at the word and paragraph levels by HCL to strengthen the local
    semantic and global thematic consistency of patent text; M-GAT models patent classification
    codes, citation relations and text semantics as heterogeneous graph structures,
    and achieves dynamic fusion of multi-source features by cross-modal gated attention;
    MSA adopts a hierarchical sparsity strategy to optimize the computational efficiency
    of long text modeling at word, phrase, sentence and paragraph granularity. Experiments
    show that the framework demonstrates significant advantages over existing deep
    learning methods in tasks such as patent classification and similarity matching,
    and provides a solution with both theoretical innovation and practical value for
    solving the problems of patent examination efficiency improvement and technology
    relevance mining.
  link: http://arxiv.org/abs/2505.20188v1
  published: '2025-05-26T16:32:43Z'
- title: "PatentMind: A Multi-Aspect Reasoning Graph for Patent Similarity\n  Evaluation"
  authors:
  - Yongmin Yoo
  - Qiongkai Xu
  - Longbing Cao
  summary: 'Patent similarity evaluation plays a critical role in intellectual property
    analysis. However, existing methods often overlook the intricate structure of
    patent documents, which integrate technical specifications, legal boundaries,
    and application contexts. We introduce PatentMind, a novel framework for patent
    similarity assessment based on a Multi-Aspect Reasoning Graph (MARG). PatentMind
    decomposes patents into three core dimensions: technical feature, application
    domain, and claim scope, to compute dimension-specific similarity scores. These
    scores are dynamically weighted through a four-stage reasoning process which integrates
    contextual signals to emulate expert-level judgment. To support evaluation, we
    construct PatentSimBench, a human-annotated benchmark comprising 500 patent pairs.
    Experimental results demonstrate that PatentMind achieves a strong correlation
    ($r=0.938$) with expert annotations, significantly outperforming embedding-based
    models and advanced prompt engineering methods.These results highlight the effectiveness
    of modular reasoning frameworks in overcoming key limitations of embedding-based
    methods for analyzing patent similarity.'
  link: http://arxiv.org/abs/2505.19347v1
  published: '2025-05-25T22:28:27Z'
- title: 'PatentScore: Multi-dimensional Evaluation of LLM-Generated Patent Claims'
  authors:
  - Yongmin Yoo
  - Qiongkai Xu
  - Longbing Cao
  summary: 'Natural language generation (NLG) metrics play a central role in evaluating
    generated texts, but are not well suited for the structural and legal characteristics
    of patent documents. Large language models (LLMs) offer strong potential in automating
    patent generation, yet research on evaluating LLM-generated patents remains limited,
    especially in evaluating the generation quality of patent claims, which are central
    to defining the scope of protection. Effective claim evaluation requires addressing
    legal validity, technical accuracy, and structural compliance. To address this
    gap, we introduce PatentScore, a multi-dimensional evaluation framework for assessing
    LLM-generated patent claims. PatentScore incorporates: (1) hierarchical decomposition
    for claim analysis; (2) domain-specific validation patterns based on legal and
    technical standards; and (3) scoring across structural, semantic, and legal dimensions.
    Unlike general-purpose NLG metrics, PatentScore reflects patent-specific constraints
    and document structures, enabling evaluation beyond surface similarity. We evaluate
    400 GPT-4o-mini generated Claim 1s and report a Pearson correlation of $r = 0.819$
    with expert annotations, outperforming existing NLG metrics. Furthermore, we conduct
    additional evaluations using open models such as Claude-3.5-Haiku and Gemini-1.5-flash,
    all of which show strong correlations with expert judgments, confirming the robustness
    and generalizability of our framework.'
  link: http://arxiv.org/abs/2505.19345v1
  published: '2025-05-25T22:20:11Z'
- title: 'Patent-CR: A Dataset for Patent Claim Revision'
  authors:
  - Lekang Jiang
  - Pascal A Scherz
  - Stephan Goetz
  summary: This paper presents Patent-CR, the first dataset created for the patent
    claim revision task in English. It includes both initial patent applications rejected
    by patent examiners and the final granted versions. Unlike normal text revision
    tasks that predominantly focus on enhancing sentence quality, such as grammar
    correction and coherence improvement, patent claim revision aims at ensuring the
    claims meet stringent legal criteria. These criteria are beyond novelty and inventiveness,
    including clarity of scope, technical accuracy, language precision, and legal
    robustness. We assess various large language models (LLMs) through professional
    human evaluation, including general LLMs with different sizes and architectures,
    text revision models, and domain-specific models. Our results indicate that LLMs
    often bring ineffective edits that deviate from the target revisions. In addition,
    domain-specific models and the method of fine-tuning show promising results. Notably,
    GPT-4 outperforms other tested LLMs, but further revisions are still necessary
    to reach the examination standard. Furthermore, we demonstrate the inconsistency
    between automated and human evaluation results, suggesting that GPT-4-based automated
    evaluation has the highest correlation with human judgment. This dataset, along
    with our preliminary empirical research, offers invaluable insights for further
    exploration in patent claim revision.
  link: http://arxiv.org/abs/2412.02549v2
  published: '2024-12-03T16:43:42Z'
- title: Can Large Language Models Generate High-quality Patent Claims?
  authors:
  - Lekang Jiang
  - Caiqi Zhang
  - Pascal A Scherz
  - Stephan Goetz
  summary: Large language models (LLMs) have shown exceptional performance across
    various text generation tasks but remain under-explored in the patent domain,
    which offers highly structured and precise language. This paper constructs a dataset
    to investigate the performance of current LLMs in patent claim generation. Our
    results demonstrate that generating claims based on patent descriptions outperforms
    previous research relying on abstracts. Interestingly, current patent-specific
    LLMs perform much worse than state-of-the-art general LLMs, highlighting the necessity
    for future research on in-domain LLMs. We also find that LLMs can produce high-quality
    first independent claims, but their performances markedly decrease for subsequent
    dependent claims. Moreover, fine-tuning can enhance the completeness of inventions'
    features, conceptual clarity, and feature linkage. Among the tested LLMs, GPT-4
    demonstrates the best performance in comprehensive human evaluations by patent
    experts, with better feature coverage, conceptual clarity, and technical coherence.
    Despite these capabilities, comprehensive revision and modification are still
    necessary to pass rigorous patent scrutiny and ensure legal robustness.
  link: http://arxiv.org/abs/2406.19465v3
  published: '2024-06-27T18:07:40Z'

date: '2026-02-10'
papers:
- title: On Protecting Agentic Systems' Intellectual Property via Watermarking
  authors:
  - Liwen Wang
  - Zongjie Li
  - Yuchong Xie
  - Shuai Wang
  - Dongdong She
  - Wei Wang
  - Juergen Rahmel
  summary: The evolution of Large Language Models (LLMs) into agentic systems that
    perform autonomous reasoning and tool use has created significant intellectual
    property (IP) value. We demonstrate that these systems are highly vulnerable to
    imitation attacks, where adversaries steal proprietary capabilities by training
    imitation models on victim outputs. Crucially, existing LLM watermarking techniques
    fail in this domain because real-world agentic systems often operate as grey boxes,
    concealing the internal reasoning traces required for verification. This paper
    presents AGENTWM, the first watermarking framework designed specifically for agentic
    models. AGENTWM exploits the semantic equivalence of action sequences, injecting
    watermarks by subtly biasing the distribution of functionally identical tool execution
    paths. This mechanism allows AGENTWM to embed verifiable signals directly into
    the visible action trajectory while remaining indistinguishable to users. We develop
    an automated pipeline to generate robust watermark schemes and a rigorous statistical
    hypothesis testing procedure for verification. Extensive evaluations across three
    complex domains demonstrate that AGENTWM achieves high detection accuracy with
    negligible impact on agent performance. Our results confirm that AGENTWM effectively
    protects agentic IP against adaptive adversaries, who cannot remove the watermarks
    without severely degrading the stolen model's utility.
  link: https://arxiv.org/abs/2602.08401v1
  published: '2026-02-09T09:02:15Z'

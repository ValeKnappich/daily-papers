date: '2025-05-31'
papers:
- title: "PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep\n\
    \  Intellectual Property Protection"
  authors:
  - Enyan Dai
  - Minhua Lin
  - Suhang Wang
  summary: Pretraining on Graph Neural Networks (GNNs) has shown great power in facilitating
    various downstream tasks. As pretraining generally requires huge amount of data
    and computational resources, the pretrained GNNs are high-value Intellectual Properties
    (IP) of the legitimate owner. However, adversaries may illegally copy and deploy
    the pretrained GNN models for their downstream tasks. Though initial efforts have
    been made to watermark GNN classifiers for IP protection, these methods require
    the target classification task for watermarking, and thus are not applicable to
    self-supervised pretraining of GNN models. Hence, in this work, we propose a novel
    framework named PreGIP to watermark the pretraining of GNN encoder for IP protection
    while maintain the high-quality of the embedding space. PreGIP incorporates a
    task-free watermarking loss to watermark the embedding space of pretrained GNN
    encoder. A finetuning-resistant watermark injection is further deployed. Theoretical
    analysis and extensive experiments show the effectiveness of {\method} in IP protection
    and maintaining high-performance for downstream tasks.
  link: http://arxiv.org/abs/2402.04435v2
  published: '2024-02-06T22:13:49Z'
- title: "Retrieval-Augmented Generation Systems for Intellectual Property via\n \
    \ Synthetic Multi-Angle Fine-tuning"
  authors:
  - Runtao Ren
  - Jian Ma
  - Jianxi Luo
  summary: Retrieval-Augmented Generation (RAG) systems in the Intellectual Property
    (IP) field often struggle with diverse user queries, including colloquial expressions,
    spelling errors, and ambiguous terminology, leading to inaccurate retrieval and
    suboptimal responses. To address this challenge, we propose Multi-Angle Question
    Generation and Retrieval Fine-Tuning Method (MQG-RFM), a novel framework that
    leverages large language models (LLMs) to simulate varied user inquiries and fine-tunes
    retrieval models to align semantically equivalent but linguistically diverse questions.
    Unlike complex architectural modifications, MQG-RFM adopts a lightweight Data-to-Tune
    paradigm, combining prompt-engineered query generation with hard negative mining
    to enhance retrieval robustness without costly infrastructure changes. Experimental
    results on a Taiwan patent Q&A dataset show 185.62% improvement in retrieval accuracy
    on the Patent Consultation dataset and 262.26% improvement on the Novel Patent
    Technology Report dataset, with 14.22% and 53.58% improvements in generation quality
    over the baselines, respectively. By bridging the gap between user intent and
    system comprehension through semantic-aware retrieval optimization, MQG-RFM offers
    a practical, scalable approach for rapid, cost-effective deployment among small
    and medium-sized agencies seeking reliable patent intelligence solutions. Additionally,
    our proposed method has already been adopted by ScholarMate, the largest professional
    research social networking platform in China, to support real-world development
    and deployment. A demo version of the instantiated is available at https://github.com/renruntao/patent_rag.
  link: http://arxiv.org/abs/2506.00527v1
  published: '2025-05-31T12:19:35Z'
